{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a74411d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emcee \n",
    "import tqdm\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import flowtorch.bijectors as bij\n",
    "import flowtorch.distributions as dist\n",
    "import flowtorch.parameters as params\n",
    "from scipy.special import logsumexp\n",
    "import numpy as np \n",
    "import matplotlib.pylab as plt \n",
    "import scipy.stats as ss \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import random\n",
    "\n",
    "# Set the seed\n",
    "random.seed(42)\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font',**{'family':'sans-serif','serif':['Palatino']})\n",
    "figSize  = (12, 8)\n",
    "fontSize = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8371af7f",
   "metadata": {},
   "source": [
    "# Setup Quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3983610",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS_2 = np.array([0.0, 2.0, -1.0])\n",
    "PARAMS_3 = np.array([0.0, 0.0, 2.0, -1.0])\n",
    "NSAMPLES = 2000\n",
    "BURNIN = 0.25\n",
    "DISCARD = int(BURNIN * NSAMPLES)\n",
    "XMIN = 0.0\n",
    "XMAX = 4.0 \n",
    "EPS = 0.75\n",
    "p = 4 # fourth order polynomial\n",
    "PARAMS_p = np.random.randn(p+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c41229",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7740bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glm_evidence(data, design, covariance):\n",
    "    \"\"\"\n",
    "    Computes the log marginal likelihood (evidence) of the data under a Gaussian linear model (GLM) with \n",
    "    a Gaussian prior on the parameters.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    data : ndarray\n",
    "        A 1D array of shape (N,) representing the observed data.\n",
    "    design : ndarray\n",
    "        A 2D array of shape (N, D) representing the design matrix, where N is the number of observations and D is the number of features.\n",
    "    covariance : ndarray\n",
    "        A 2D array of shape (N, N) representing the covariance matrix of the noise in the observations.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    log_evidence : float\n",
    "        The log of the marginal likelihood (evidence) of the data given the model, prior, and noise covariance.\n",
    "    \n",
    "    Notes:\n",
    "    ------\n",
    "    The function assumes a Gaussian prior on the model parameters with mean zero and identity covariance. \n",
    "    The log marginal likelihood is computed by integrating out the parameters, resulting in a marginal distribution \n",
    "    that depends on the prior, the design matrix, and the noise covariance.\n",
    "    \"\"\"\n",
    "\n",
    "    priormean = np.zeros(design.shape[1])\n",
    "    priorcov = np.eye(design.shape[1])\n",
    "    mean = design @ priormean \n",
    "    cov = covariance + design @ priorcov @ design.T \n",
    "    dist = ss.multivariate_normal(mean, cov)\n",
    "    return dist.logpdf(data)\n",
    "\n",
    "def generate_data(params, xmin=0, xmax=2, ndata=50, eps=0.02):\n",
    "    \"\"\"\n",
    "    Generate synthetic data using a polynomial model with Gaussian noise.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    params : array-like\n",
    "        Coefficients of the polynomial model. The length of this array determines\n",
    "        the degree of the polynomial.\n",
    "    xmin : float, optional\n",
    "        The minimum x-value of the generated data (default is 0).\n",
    "    xmax : float, optional\n",
    "        The maximum x-value of the generated data (default is 2).\n",
    "    ndata : int, optional\n",
    "        The number of data points to generate (default is 50).\n",
    "    eps : float, optional\n",
    "        Standard deviation of the Gaussian noise added to the data (default is 0.02).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    xvalues : numpy.ndarray\n",
    "        1D array of x-values over the range [xmin, xmax].\n",
    "    data : numpy.ndarray\n",
    "        1D array of generated y-values (data) with added Gaussian noise.\n",
    "    covariance : numpy.ndarray\n",
    "        Covariance matrix of the noise, a diagonal matrix with variance `eps**2`.\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    The function generates `ndata` points of synthetic data based on a polynomial \n",
    "    model with the given coefficients `params`. The polynomial degree is determined \n",
    "    by the length of `params`. Gaussian noise is added to the data, with variance \n",
    "    controlled by `eps`.\n",
    "    \"\"\"\n",
    "    degree = len(params)-1\n",
    "    xvalues = np.linspace(xmin, xmax, ndata).reshape(-1, 1)\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    poly.fit(xvalues)\n",
    "    design = poly.transform(xvalues)\n",
    "    covariance = np.eye(ndata) * eps**2 \n",
    "    data = design @ params + np.random.multivariate_normal(np.zeros(ndata), covariance, 1)\n",
    "    return xvalues.reshape(-1), data.reshape(-1), covariance\n",
    "\n",
    "def loglikelihood(theta, data, design, covariance):\n",
    "    \"\"\"\n",
    "    Compute the log-likelihood of the data given a model parameterized by theta.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    theta : array-like\n",
    "        A 1D array representing the model parameters. These parameters are used to compute \n",
    "        the mean of the multivariate normal distribution by multiplying with the design matrix.\n",
    "    data : array-like\n",
    "        A 1D array of observed data for which the log-likelihood is computed.\n",
    "    design : ndarray\n",
    "        A 2D array (design matrix) where each row corresponds to an observation and each column \n",
    "        corresponds to a model feature or predictor. The design matrix is used to compute the mean \n",
    "        of the multivariate normal distribution.\n",
    "    covariance : ndarray\n",
    "        A 2D square matrix representing the covariance of the data. This matrix captures the \n",
    "        uncertainties in the data and is used in the multivariate normal distribution.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    float\n",
    "        The log-likelihood value, which represents the log of the probability density function (pdf) \n",
    "        evaluated at the observed data, given the model parameters `theta`.\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - This function assumes a multivariate normal likelihood, where the mean of the distribution is \n",
    "      computed as the product of the design matrix and the model parameters `theta`, and the covariance \n",
    "      is provided as input.\n",
    "    - The log-likelihood is used in Bayesian inference and Maximum Likelihood Estimation (MLE) to \n",
    "      assess how well the model, parameterized by `theta`, explains the observed data.\n",
    "    - The `scipy.stats.multivariate_normal` class is used to compute the log-probability density.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    If you have a model with parameter `theta`, design matrix `X`, observed data `y`, and covariance \n",
    "    matrix `Sigma`, you can compute the log-likelihood as:\n",
    "    \n",
    "    >>> loglikelihood(theta, y, X, Sigma)\n",
    "    \"\"\"\n",
    "\n",
    "    mean = design @ theta\n",
    "    dist = ss.multivariate_normal(mean, covariance)\n",
    "    return dist.logpdf(data)\n",
    "\n",
    "def logprior(theta):\n",
    "    \"\"\"\n",
    "    Compute the log-prior probability density of the model parameters theta under a multivariate normal prior.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    theta : array-like\n",
    "        A 1D or 2D array representing the model parameters. If a 1D array is passed, it will be converted to \n",
    "        a 2D array where each row is a set of parameters. The shape of `theta` is (n_samples, n_params), where\n",
    "        n_samples is the number of parameter sets and n_params is the number of parameters in each set.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    float\n",
    "        The log-prior value of the parameter set `theta`, assuming a multivariate normal prior distribution \n",
    "        with zero mean and identity covariance matrix.\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - This function assumes a standard multivariate normal prior with a mean of zero and an identity \n",
    "      covariance matrix, i.e., `N(0, I)`, where `I` is the identity matrix.\n",
    "    - The log-prior is often used in Bayesian inference to quantify the prior belief about the model parameters \n",
    "      before observing any data. It reflects how likely certain parameter values are based on prior knowledge.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    If you have a parameter vector `theta`, you can compute its log-prior as follows:\n",
    "    \n",
    "    >>> logprior(theta)\n",
    "    \n",
    "    This will return the log of the prior probability density of `theta` assuming a multivariate normal \n",
    "    prior with zero mean and identity covariance.\n",
    "\n",
    "    \"\"\"\n",
    "    theta = np.atleast_2d(theta)\n",
    "    nparams = theta.shape[1]\n",
    "    mean = np.zeros(nparams)\n",
    "    cov = np.eye(nparams)\n",
    "    dist = ss.multivariate_normal(mean, cov)\n",
    "    return dist.logpdf(theta)\n",
    "\n",
    "def logposterior(theta, data, design, covariance):\n",
    "    \"\"\"\n",
    "    Compute the log-posterior probability density of the model parameters `theta` given the data, design matrix,\n",
    "    and covariance matrix. The log-posterior is the sum of the log-likelihood and the log-prior.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    theta : array-like\n",
    "        A 1D or 2D array representing the model parameters. If a 1D array is passed, it will be converted to\n",
    "        a 2D array where each row is a set of parameters. The shape of `theta` is (n_samples, n_params), where\n",
    "        n_samples is the number of parameter sets and n_params is the number of parameters in each set.\n",
    "        \n",
    "    data : array-like\n",
    "        The observed data for which the likelihood is calculated. Should match the number of observations expected\n",
    "        by the design matrix.\n",
    "\n",
    "    design : array-like\n",
    "        The design matrix used to model the relationship between the data and the parameters. Should have shape\n",
    "        (n_data, n_params), where n_data is the number of observations and n_params is the number of parameters.\n",
    "\n",
    "    covariance : array-like\n",
    "        The covariance matrix used in the likelihood calculation. Should be a square matrix of shape\n",
    "        (n_data, n_data) representing the covariance of the data.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    float\n",
    "        The log-posterior value of the parameter set `theta`, computed as the sum of the log-likelihood and \n",
    "        the log-prior.\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - The log-posterior combines information from both the likelihood of the observed data given the parameters\n",
    "      and the prior belief about the parameters. It is used in Bayesian inference to update the prior belief\n",
    "      in light of observed data.\n",
    "    - This function assumes that the `loglikelihood` and `logprior` functions are defined and properly\n",
    "      compute the log-likelihood and log-prior, respectively.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    To compute the log-posterior for a given parameter set `theta`, data, design matrix, and covariance matrix:\n",
    "\n",
    "    >>> logposterior(theta, data, design, covariance)\n",
    "\n",
    "    This will return the log of the posterior probability density of `theta` given the observed data and the prior.\n",
    "\n",
    "    \"\"\"\n",
    "    logl = loglikelihood(theta, data, design, covariance)\n",
    "    logp = logprior(theta)\n",
    "    return logl + logp\n",
    "\n",
    "def sampling(nsamples, initial, data, design, covariance, stepsize=1E-4):\n",
    "    \"\"\"\n",
    "    Perform Markov Chain Monte Carlo (MCMC) sampling using the `emcee` library to explore the parameter space\n",
    "    and estimate the posterior distribution of the model parameters.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    nsamples : int\n",
    "        The number of MCMC samples to draw from the posterior distribution.\n",
    "\n",
    "    initial : array-like\n",
    "        The initial parameter values to start the MCMC sampling. Should be a 1D array of length `ndim` where\n",
    "        `ndim` is the number of parameters.\n",
    "\n",
    "    data : array-like\n",
    "        The observed data to be used in the likelihood calculation. Should be compatible with the design matrix.\n",
    "\n",
    "    design : array-like\n",
    "        The design matrix used in the likelihood calculation. Should have dimensions (n_data, n_params), where\n",
    "        `n_data` is the number of observations and `n_params` is the number of parameters.\n",
    "\n",
    "    covariance : array-like\n",
    "        The covariance matrix used in the likelihood calculation. Should be a square matrix of shape\n",
    "        (n_data, n_data) representing the covariance of the data.\n",
    "\n",
    "    stepsize : float, optional, default=1E-4\n",
    "        The standard deviation of the normal distribution used to initialize the walker positions. Controls the\n",
    "        size of the initial perturbations to the starting positions.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    sampler : emcee.EnsembleSampler\n",
    "        The `emcee` sampler object after running the MCMC. This object contains the samples, chain information,\n",
    "        and other useful diagnostic information.\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - The function initializes a set of walkers around the `initial` parameter values, perturbed by a small random\n",
    "      noise defined by `stepsize`.\n",
    "    - The `emcee` library is used for the MCMC sampling. It explores the posterior distribution defined by the\n",
    "      `logposterior` function, which combines the log-likelihood and log-prior.\n",
    "    - The number of walkers is set to twice the number of dimensions (`ndim`), which is a common practice to ensure\n",
    "      adequate exploration of the parameter space.\n",
    "    - Progress of the sampling is shown through a progress bar if the `progress` argument is set to `True`.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    To perform MCMC sampling with 1000 samples starting from an initial guess:\n",
    "\n",
    "    >>> sampler = sampling(1000, initial_guess, data, design, covariance)\n",
    "\n",
    "    This will return an `emcee.EnsembleSampler` object containing the MCMC results.\n",
    "\n",
    "    \"\"\"\n",
    "    ndim = len(initial)\n",
    "    nwalkers = len(initial) * 2\n",
    "    pos = initial + stepsize * np.random.randn(nwalkers, ndim)\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, logposterior, args=(data, design, covariance))\n",
    "    sampler.run_mcmc(pos, nsamples, progress=True)\n",
    "    return sampler\n",
    "\n",
    "class ThetaTransform:\n",
    "    \"\"\"\n",
    "    A class to perform a linear transformation on parameter samples using a Cholesky decomposition \n",
    "    of their covariance matrix. The transformation standardizes the parameters such that they are \n",
    "    transformed to a new space where their covariance is the identity matrix.\n",
    "\n",
    "    Attributes:\n",
    "    ----------\n",
    "    ndim : int\n",
    "        The number of dimensions of the parameter samples.\n",
    "    pcov : ndarray\n",
    "        Covariance matrix of the input samples.\n",
    "    chol : ndarray\n",
    "        Cholesky decomposition (lower triangular) of the covariance matrix.\n",
    "    chol_inv : ndarray\n",
    "        Inverse of the Cholesky decomposition.\n",
    "    mean : ndarray\n",
    "        Mean vector of the input samples.\n",
    "    logdetchol : float\n",
    "        Logarithm of the determinant of the Cholesky matrix.\n",
    "\n",
    "    Methods:\n",
    "    -------\n",
    "    forward(parameter):\n",
    "        Transforms the input parameters to the standardized space using the inverse Cholesky transform.\n",
    "    \n",
    "    inverse(parameterprime):\n",
    "        Transforms parameters from the standardized space back to the original parameter space.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, samples):\n",
    "        \"\"\"\n",
    "        Initializes the ThetaTransform object with parameter samples.\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        samples : ndarray\n",
    "            A 2D array of shape (N, D) where N is the number of samples and D is the dimensionality of the parameters.\n",
    "        \"\"\"\n",
    "        self.ndim = samples.shape[1]\n",
    "        self.pcov = np.cov(samples.T)\n",
    "        self.chol = np.linalg.cholesky(self.pcov)\n",
    "        self.chol_inv = np.linalg.inv(self.chol)\n",
    "        self.mean = np.mean(samples, axis=0).reshape(-1, self.ndim)\n",
    "        self.logdetchol = np.linalg.slogdet(self.chol)[1]\n",
    "\n",
    "    def forward(self, parameter):\n",
    "        \"\"\"\n",
    "        Transforms the input parameter(s) to the standardized space using the inverse Cholesky decomposition.\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        parameter : ndarray\n",
    "            A 1D or 2D array of shape (D,) or (N, D) where D is the dimensionality of the parameters and N is the number of parameter sets.\n",
    "        \n",
    "        Returns:\n",
    "        -------\n",
    "        parameterprime : ndarray\n",
    "            The transformed parameter(s) in the standardized space, with the same shape as the input.\n",
    "        \"\"\"\n",
    "        parameter = parameter.reshape(-1, self.ndim)\n",
    "        parameterprime = self.chol_inv @ (parameter - self.mean).T\n",
    "        return parameterprime.T\n",
    "\n",
    "    def inverse(self, parameterprime):\n",
    "        \"\"\"\n",
    "        Transforms the parameter(s) from the standardized space back to the original parameter space.\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        parameterprime : ndarray\n",
    "            A 1D or 2D array of shape (D,) or (N, D) where D is the dimensionality of the standardized parameters and N is the number of parameter sets.\n",
    "        \n",
    "        Returns:\n",
    "        -------\n",
    "        parameter : ndarray\n",
    "            The parameter(s) transformed back to the original space, with the same shape as the input.\n",
    "        \"\"\"\n",
    "        parameterprime = parameterprime.reshape(-1, self.ndim)\n",
    "        parameter = self.chol @ parameterprime.T + self.mean.T\n",
    "        return parameter.T\n",
    "\n",
    "    \n",
    "def build_network(hidden=(32, 32, 32)):\n",
    "    \"\"\"Creates a function to do the mapping\n",
    "\n",
    "    Args:\n",
    "        hidden (tuple, optional): Number of hidden layers. Defaults to (32, 32, 32).\n",
    "\n",
    "    Returns:\n",
    "        flowtorch.lazy.lazy: a composition of bijectors\n",
    "    \"\"\"\n",
    "\n",
    "    transforms = bij.Compose(\n",
    "        bijectors=[\n",
    "            bij.AffineAutoregressive(\n",
    "                params.DenseAutoregressive(hidden_dims=hidden, nonlinearity=nn.Tanh),\n",
    "            ),\n",
    "            bij.AffineAutoregressive(\n",
    "                params.DenseAutoregressive(hidden_dims=hidden, nonlinearity=nn.Tanh),\n",
    "            ),\n",
    "            bij.AffineAutoregressive(\n",
    "                params.DenseAutoregressive(hidden_dims=hidden, nonlinearity=nn.Tanh),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    return transforms\n",
    "\n",
    "class NormFlow:\n",
    "    def __init__(self, samples):\n",
    "\n",
    "        ndim = samples.shape[1]\n",
    "        mean = torch.zeros(ndim)\n",
    "        std = torch.ones(ndim)\n",
    "        self.dataset = torch.tensor(samples, dtype=torch.float)\n",
    "        dist_x = torch.distributions.Independent(\n",
    "            torch.distributions.Normal(mean, std), 1\n",
    "        )\n",
    "        bijector = build_network(hidden=(16, 16, 16))\n",
    "        self.dist_y = dist.Flow(dist_x, bijector)\n",
    "\n",
    "    def training(self, lr: float = 5e-3, nsteps: int = 1000) -> list:\n",
    "        \"\"\"Train the normalising flow\n",
    "\n",
    "        Args:\n",
    "            lr (float, optional): the learning rate. Defaults to 5e-3.\n",
    "            nsteps (int, optional): the number of steps. Defaults to 1000.\n",
    "\n",
    "        Returns:\n",
    "            list: a list of the loss values at each iteration.\n",
    "        \"\"\"\n",
    "        optimizer = torch.optim.Adam(self.dist_y.parameters(), lr=lr)\n",
    "        record = []\n",
    "        interval = divmod(nsteps, 20)[0]\n",
    "        with tqdm.trange(nsteps) as bar:\n",
    "            for step in bar:\n",
    "                optimizer.zero_grad()\n",
    "                loss = -self.dist_y.log_prob(self.dataset).mean()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                record.append(loss.item())\n",
    "                postfix = dict(Loss=f\"{loss.item():.3f}\")\n",
    "                bar.set_postfix(postfix)\n",
    "        return record\n",
    "\n",
    "\n",
    "    def logpdf(self, parameter: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Calculates the log-probability of the flow given a sample.\n",
    "\n",
    "        Args:\n",
    "            parameter (np.ndarray): a test point in Cosmological parameter space.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: the log-probability value.\n",
    "        \"\"\"\n",
    "        p_tensor = torch.tensor(parameter, dtype=torch.float)\n",
    "        return self.dist_y.log_prob(p_tensor).detach().numpy()\n",
    "\n",
    "def evidence_estimate(samples, log_post, trainflow=False, lr=1E-3, nsteps=3000, nsamplesflow=10000):\n",
    "    \"\"\"\n",
    "    Estimate the Bayesian model evidence (marginal likelihood) using transformed samples \n",
    "    and log-posterior values, with the option to use a normalizing flow model for prior density estimation.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    samples : array-like\n",
    "        An array of shape (n_samples, n_params) containing the MCMC samples of the model parameters.\n",
    "        Each row corresponds to a set of parameter values.\n",
    "    \n",
    "    log_post : array-like\n",
    "        An array of shape (n_samples,) containing the log-posterior values for each sample in `samples`.\n",
    "\n",
    "    trainflow : bool, optional, default=False\n",
    "        A flag to indicate whether to use a normalizing flow model to estimate the prior probability density\n",
    "        for the transformed samples. If set to `True`, a flow-based model is trained and used to estimate\n",
    "        `log_pdf_prime`. If `False`, a standard multivariate normal prior is assumed.\n",
    "\n",
    "    lr : float, optional, default=1E-3\n",
    "        The learning rate for training the normalizing flow model, if `trainflow` is set to `True`.\n",
    "\n",
    "    nsteps : int, optional, default=3000\n",
    "        The number of optimization steps for training the normalizing flow model, if `trainflow` is set to `True`.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    logevidence : float\n",
    "        The natural logarithm of the Bayesian evidence (marginal likelihood). This value provides a measure\n",
    "        of how well the model fits the data, marginalized over the parameter space.\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - The function first transforms the `samples` to a new space using the `ThetaTransform` class, which normalizes\n",
    "      the covariance structure of the samples.\n",
    "    - If `trainflow` is `True`, a normalizing flow model (`NormFlow`) is trained to estimate the log probability density\n",
    "      of the transformed samples (`log_pdf_prime`). The flow is trained using the specified learning rate (`lr`)\n",
    "      and number of optimization steps (`nsteps`).\n",
    "    - If `trainflow` is `False`, the log-prior is computed assuming a standard multivariate normal prior.\n",
    "    - The evidence is computed using the log-determinant of the Cholesky decomposition from the transformation,\n",
    "      and the log-posterior values with either the prior or flow-based density.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    To estimate the log evidence using MCMC samples and train a normalizing flow:\n",
    "\n",
    "    >>> logevidence = evidence_estimate(mcmc_samples, log_posteriors, trainflow=True, lr=1E-3, nsteps=5000)\n",
    "\n",
    "    This will return the log evidence of the model, using a trained flow to estimate the log-prior in the transformed space.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    nsamples = samples.shape[0]\n",
    "    \n",
    "    if trainflow:\n",
    "        nsamples_prime = min([nsamples, nsamplesflow])\n",
    "        print(f'We are using {nsamples_prime} samples in the Normalising Flow.')\n",
    "        \n",
    "        idx = random.sample(range(0, nsamples), nsamples_prime)\n",
    "        samples_chosen = samples[idx]\n",
    "        transform = ThetaTransform(samples_chosen)\n",
    "        samples_prime = transform.forward(samples_chosen)\n",
    "        \n",
    "        flow = NormFlow(samples_prime)\n",
    "        flow.training(lr=lr, nsteps=nsteps)\n",
    "        log_pdf_prime = flow.logpdf(samples_prime)\n",
    "        \n",
    "        logevidence = transform.logdetchol + logsumexp(log_post[idx] - log_pdf_prime) - np.log(nsamples_prime)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        transform = ThetaTransform(samples)\n",
    "        samples_prime = transform.forward(samples)\n",
    "        log_pdf_prime = logprior(samples_prime)\n",
    "        log_sum_exp = logsumexp(log_post - log_pdf_prime)\n",
    "        logevidence = transform.logdetchol +  log_sum_exp - np.log(nsamples)\n",
    "        print(f'log-sum-exp term is {log_sum_exp:.3f}')\n",
    "        \n",
    "    print(f'log-determinant of the Cholesky factor is {transform.logdetchol:.3f}')\n",
    "    \n",
    "    return logevidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434b7715",
   "metadata": {},
   "source": [
    "# Data and Design Matrics (Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80ab3243",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvalues, data, datacov = generate_data(PARAMS_2, xmin=XMIN, xmax=XMAX, eps=EPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc472d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "design_order_2 = PolynomialFeatures(degree=2).fit_transform(xvalues.reshape(-1,1))\n",
    "design_order_3 = PolynomialFeatures(degree=3).fit_transform(xvalues.reshape(-1,1))\n",
    "design_order_p = PolynomialFeatures(degree=p).fit_transform(xvalues.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ac7af9",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fec439e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:05<00:00, 376.87it/s]\n"
     ]
    }
   ],
   "source": [
    "sampler_2 = sampling(NSAMPLES, PARAMS_2, data, design_order_2, datacov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c72641ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:06<00:00, 294.31it/s]\n"
     ]
    }
   ],
   "source": [
    "sampler_3 = sampling(NSAMPLES, PARAMS_3, data, design_order_3, datacov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e8f7060",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:08<00:00, 238.88it/s]\n"
     ]
    }
   ],
   "source": [
    "sampler_p = sampling(NSAMPLES, PARAMS_p, data, design_order_p, datacov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791db1a7",
   "metadata": {},
   "source": [
    "# Evidence Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cc2a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_2  = sampler_2.get_chain(discard=DISCARD, flat=True)\n",
    "log_post_2 = sampler_2.get_log_prob(discard=DISCARD, flat=True)\n",
    "\n",
    "samples_3  = sampler_3.get_chain(discard=DISCARD, flat=True)\n",
    "log_post_3 = sampler_3.get_log_prob(discard=DISCARD, flat=True)\n",
    "\n",
    "samples_p  = sampler_p.get_chain(discard=DISCARD, flat=True)\n",
    "log_post_p = sampler_p.get_log_prob(discard=DISCARD, flat=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d8f3d3-a1bf-4fbc-a75d-51476b7ead42",
   "metadata": {},
   "source": [
    "### Quadratic Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2aa1fd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-57.48981608876696"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_evidence(data, design_order_2, datacov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d47ff00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log-sum-exp term is -41.207\n",
      "log-determinant of the Cholesky factor is -7.178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-57.490615770115944"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evidence_estimate(samples_2, log_post_2, trainflow=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36f8d6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using 9000 samples in the Normalising Flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 3000/3000 [01:26<00:00, 34.57it/s, Loss=4.112]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log-determinant of the Cholesky factor is -7.178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-57.457018077118555"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evidence_estimate(samples_2, log_post_2, trainflow=True, lr=1e-3, nsteps=3000, nsamplesflow=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e6f09c-15e3-4d50-a7b0-97aeff306719",
   "metadata": {},
   "source": [
    "### Cubic Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b1b1d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-58.52034976621188"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_evidence(data, design_order_3, datacov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a01cddab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log-sum-exp term is -39.054\n",
      "log-determinant of the Cholesky factor is -10.074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-58.52071427984631"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evidence_estimate(samples_3, log_post_3, trainflow=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5744fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using 10000 samples in the Normalising Flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 3000/3000 [02:17<00:00, 21.90it/s, Loss=5.439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log-determinant of the Cholesky factor is -10.082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-58.51459930949328"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evidence_estimate(samples_3, log_post_3, trainflow=True, lr=1e-3, nsteps=3000, nsamplesflow=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5fa8fa-b5ef-44b8-9098-aac0242f9754",
   "metadata": {},
   "source": [
    "### Quartic Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "634ef815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-61.52278729088876"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_evidence(data, design_order_p, datacov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10b3f27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log-sum-exp term is -38.681\n",
      "log-determinant of the Cholesky factor is -13.228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-61.52406054668519"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evidence_estimate(samples_p, log_post_p, trainflow=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd186e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using 10000 samples in the Normalising Flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 3000/3000 [02:06<00:00, 23.77it/s, Loss=6.653]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log-determinant of the Cholesky factor is -13.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-60.999026697973505"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evidence_estimate(samples_p, log_post_p, trainflow=True, lr=1e-3, nsteps=3000, nsamplesflow=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9926329",
   "metadata": {},
   "source": [
    "# Plot Data and Best Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e59cf0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestfit_2 = generate_data(samples_2.mean(0), xmin=XMIN, xmax=XMAX, ndata=1000, eps=1E-10)\n",
    "bestfit_3 = generate_data(samples_3.mean(0), xmin=XMIN, xmax=XMAX, ndata=1000, eps=1E-10)\n",
    "bestfit_p = generate_data(samples_p.mean(0), xmin=XMIN, xmax=XMAX, ndata=1000, eps=1E-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5817e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.errorbar(xvalues, data, yerr=EPS, fmt='ro', markersize = 2, label = 'Data')\n",
    "plt.plot(bestfit_2[0], bestfit_2[1], lw = 3, label = 'Quadratic', linestyle = '-')\n",
    "plt.plot(bestfit_3[0], bestfit_3[1], lw = 3, label = 'Cubic', linestyle = '--')\n",
    "plt.plot(bestfit_p[0], bestfit_p[1], lw = 3, label = 'Quartic', linestyle = ':')\n",
    "plt.ylabel(r'$f(x)$', fontsize = fontSize)\n",
    "plt.xlabel(r'$x$', fontsize = fontSize)\n",
    "plt.tick_params(axis='x', labelsize=fontSize)\n",
    "plt.tick_params(axis='y', labelsize=fontSize)\n",
    "plt.legend(loc = 'best',prop={'family':'sans-serif', 'size':12})\n",
    "plt.savefig('plots/glm.pdf', bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933b2640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
